{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scripts fits parabolas for mdh1 and dpy23 datasets \n",
    "# and find the mean value that can be applied to the intron channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv as csv\n",
    "\n",
    "# general \n",
    "import os\n",
    "import glob\n",
    "from functools import reduce\n",
    "import re\n",
    "import sys as sys\n",
    "\n",
    "from numpy import polyval\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for loading one data-set\n",
    "def load_data(file_path):\n",
    "    data = np.loadtxt(file_path, delimiter = '\\t', skiprows=0)\n",
    "    # print(data.shape) \n",
    "    # handles some weird cases, e.g. when there is no data in the file\n",
    "    if (len(data.shape) < 2):\n",
    "        data = data[None, :]\n",
    "    if (data.shape[1] == 0):\n",
    "        I = np.array([0])\n",
    "        z = np.array([0])\n",
    "    else:\n",
    "        I = data[:, -1]\n",
    "        z = data[:, -2]\n",
    "    return (z, I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def g_x(a, x):\n",
    "    return polyval(a, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# general setup for pretty images \n",
    "# num_files = 16\n",
    "# lines_params = np.zeros([num_files, 2])\n",
    "# channel_id = 1 # 1,2,3\n",
    "# folder_path = '/Users/kkolyva/Desktop/2018-04-18-08-29-25-test/test/2018-04-24-15-33-21-median-median-first-test/csv/' \n",
    "#  image = 'N2_dpy-23_ex_int_ama-1_016'\n",
    "Ia_min, Ia_max = 0, 40000\n",
    "za_min, za_max = 0, 55\n",
    "\n",
    "# TODO: make this one a global argument\n",
    "folder_path = '/Volumes/Funky-space/Klim/2018-08-10-SEA-12/'\n",
    "experiment_name = 'SEA-12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# possible labels \n",
    "stain = ['DPY-23_EX', 'WDR-5.2', 'MDH-1']\n",
    "stage = 'E' # only embryos\n",
    "comment = '' # only empty ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# important indices\n",
    "stain_columns = ['C0_stain', 'C1_stain', 'C2_stain', 'C3_stain', 'C4_stain']\n",
    "type_columns = ['C0_type', 'C1_type', 'C2_type', 'C3_type', 'C4_type']\n",
    "stain_prefix = np.array([['C1-', 'C2-', 'C3-', 'C4-', 'C5-']])\n",
    "ext = '.csv'\n",
    "filename_column = 'new filename'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read the db and parse images that we want to process\n",
    "df = pd.read_csv(folder_path + \"smFISH-database/\" + experiment_name + \"-Table 1.csv\", sep=',', na_values=['']);\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this is general\n",
    "# filter to have only *good* and *embryo* files\n",
    "good_indices = np.logical_and((df['stage'] == stage).tolist() , (df['comment'].isnull()).tolist())\n",
    "good_indices.shape[0]\n",
    "print(np.sum(good_indices == True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose necessary stains\n",
    "dataset1 = []\n",
    "df_good = (df[type_columns].astype(np.object) == stain[0]).loc[good_indices, :]\n",
    "row, col = np.where(df_good)\n",
    "n_samples = df.shape[0]\n",
    "new_prefix = np.repeat(stain_prefix, n_samples, axis=0)[row, col]\n",
    "new_filename = df[filename_column].loc[good_indices].as_matrix()[row]\n",
    "dataset1 = [\"{}{}\".format(a_, b_) for a_, b_ in zip(new_prefix, new_filename)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose necessary stains\n",
    "dataset2 = []\n",
    "df_good = (df[type_columns].astype(np.object) == stain[1]).loc[good_indices, :]\n",
    "row, col = np.where(df_good)\n",
    "n_samples = df.shape[0]\n",
    "new_prefix = np.repeat(stain_prefix, n_samples, axis=0)[row, col]\n",
    "new_filename = df[filename_column].loc[good_indices].as_matrix()[row]\n",
    "dataset2 = [\"{}{}\".format(a_, b_) for a_, b_ in zip(new_prefix, new_filename)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose necessary stains\n",
    "dataset3 = []\n",
    "df_good = (df[type_columns].astype(np.object) == stain[2]).loc[good_indices, :]\n",
    "row, col = np.where(df_good)\n",
    "n_samples = df.shape[0]\n",
    "new_prefix = np.repeat(stain_prefix, n_samples, axis=0)[row, col]\n",
    "new_filename = df[filename_column].loc[good_indices].as_matrix()[row]\n",
    "dataset3 = [\"{}{}\".format(a_, b_) for a_, b_ in zip(new_prefix, new_filename)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_title(path, name_id=-1):\n",
    "    # get the name of the initial image\n",
    "    image_name = path.split(\"/\")[name_id] # was 8\n",
    "    # print(path.split(\"/\"))\n",
    "    # create the full title \n",
    "    title = image_name[:-4]\n",
    "    return title\n",
    "# create_title(\"/Users/kkolyva/Desktop/n2/N2-results/all/C1-N2_9.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# actual plotting \n",
    "dataset_mdh1 = []\n",
    "dataset_dpy23 = []\n",
    "p_dataset_mdh1 = []\n",
    "p_dataset_dpy23 = []\n",
    "\n",
    "for j in range(0, len(dataset1)):\n",
    "    # tmp = folder_path + \"csv-before/\" + dataset1[j] + \".csv\"\n",
    "    dataset_dpy23.append(dataset1[j])\n",
    "    # tmp = folder_path + \"csv-parameters/\" + dataset1[j] + \".csv\"\n",
    "    p_dataset_dpy23.append(dataset1[j])\n",
    "    # print(tmp)\n",
    "    \n",
    "for j in range(0, len(dataset3)):\n",
    "    # tmp = folder_path + \"csv-before/\" + dataset3[j] + \".csv\"\n",
    "    dataset_mdh1.append(dataset3[j])\n",
    "    # tmp = folder_path + \"csv-parameters/\" + dataset3[j] + \".csv\"\n",
    "    p_dataset_mdh1.append(dataset3[j])\n",
    "    # print(tmp)\n",
    "    \n",
    "    \n",
    "# to be sure that the results are consistent\n",
    "# dataset_dpy23 = np.sort(dataset_dpy23)\n",
    "# dataset_mdh1 = np.sort(dataset_mdh1)\n",
    "\n",
    "# p_dataset_dpy23 = np.sort(p_dataset_dpy23)\n",
    "# p_dataset_mdh1 = np.sort(p_dataset_mdh1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the parameters from file for the fitter\n",
    "def load_params(file_path):\n",
    "    data = np.loadtxt(file_path, delimiter = '\\t', skiprows=0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = ['DPY-23_EX', 'MDH-1', \"DPY-23_IN\"] # ['DPY-23_EX', 'WDR-5.2', 'MDH-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to normalize the z-correction curve \n",
    "def norm_z(x, y):\n",
    "    scale = np.max(x) - np.min(x)\n",
    "    x_normed = (x - np.min(x))/scale\n",
    "    y_normed = y / scale \n",
    "    return (x_normed, y_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shift so that intensity value starts at val = 0.5\n",
    "def shift_z(y, top = 0.5):\n",
    "    y_shift = y - np.max(y) + top \n",
    "    return y_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_min_max(x1, x2):\n",
    "    lb = np.max([np.min(x1), np.min(x2)])\n",
    "    rb = np.min([np.max(x1), np.max(x2)])\n",
    "    return lb, rb\n",
    "\n",
    "def find_min_max_idx(x1, x2):\n",
    "    idx_x1 = np.argmin(x1)\n",
    "    idx_x2 = np.argmin(x2)\n",
    "    if (np.min(x1) > np.min(x2)):\n",
    "        idx_lb = idx_x1\n",
    "    else:\n",
    "        idx_lb = idx_x2\n",
    "        \n",
    "    idx_x1 = np.argmax(x1)\n",
    "    idx_x2 = np.argmax(x2)\n",
    "    if (np.max(x1) > np.max(x2)):\n",
    "        idx_rb = idx_x2\n",
    "    else:\n",
    "        idx_rb = idx_x1\n",
    "        \n",
    "    return idx_lb, idx_rb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find the average curve of 2 curves\n",
    "def compute_average_curve(coeff1, coeff2):\n",
    "    return (coeff1 + coeff2)/2\n",
    "compute_average_curve(np.array([1,2,3]), np.array([2,4,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s_dataset_mdh1 = folder_path + \"csv-before/\" + img_name_mdh1 + \".csv\"\n",
    "s_dataset_dpy23 = folder_path + \"csv-before/\" + img_name_dpy23 + \".csv\"\n",
    "\n",
    "z_dpy23, I_dpy23 = load_data(s_dataset_dpy23)\n",
    "z_mdh1, I_mdh1 = load_data(s_dataset_mdh1)\n",
    "\n",
    "print(find_min_max(z_dpy23, z_mdh1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot of all ovelaping images\n",
    "# have to figure out what are the min-max value\n",
    "z_min = sys.float_info.max\n",
    "z_max = -sys.float_info.max\n",
    "\n",
    "# dataset_dpy23 and dataset_mdh1 sizes are the same\n",
    "for img_name_mdh1 in dataset_mdh1:\n",
    "    s_dataset_mdh1 = folder_path + \"csv-before/\" + img_name_mdh1 + \".csv\"\n",
    "    ps_dataset_mdh1 = folder_path + \"csv-parameters/\" + img_name_mdh1 + \".csv\"\n",
    "    img_name_dpy23 = \"C1-\" + img_name_mdh1[3:]\n",
    "    s_dataset_dpy23 = folder_path + \"csv-before/\" + img_name_dpy23 + \".csv\"\n",
    "    ps_dataset_dpy23 = folder_path + \"csv-parameters/\" + img_name_dpy23 + \".csv\"\n",
    "    \n",
    "    if(not os.path.exists(s_dataset_mdh1) or not os.path.exists(s_dataset_dpy23)):\n",
    "        # print(\"doesn't exist\")\n",
    "        continue\n",
    "    try:\n",
    "        # print(\"Processing:\", dataset[idx]) \n",
    "        z_dpy23, I_dpy23 = load_data(s_dataset_dpy23)\n",
    "        z_mdh1, I_mdh1 = load_data(s_dataset_mdh1)\n",
    "        \n",
    "        if (np.max(z_dpy23) > z_max):\n",
    "            z_max = np.max(z_dpy23)\n",
    "        if (np.max(z_mdh1) > z_max):\n",
    "            z_max = np.max(z_mdh1)\n",
    "        \n",
    "        if (np.min(z_dpy23) < z_min):\n",
    "            z_min = np.min(z_dpy23)\n",
    "        if (np.min(z_mdh1)  < z_min):\n",
    "            z_min = np.min(z_mdh1)\n",
    "               \n",
    "    except(ValueError, StopIteration, RuntimeError):\n",
    "        print(\"Caught the error for you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# actual plotting \n",
    "# dataset_dpy23 and dataset_mdh1 sizes are the same\n",
    "for img_name_mdh1 in dataset_mdh1:\n",
    "    s_dataset_mdh1 = folder_path + \"csv-before/\" + img_name_mdh1 + \".csv\"\n",
    "    ps_dataset_mdh1 = folder_path + \"csv-parameters/\" + img_name_mdh1 + \".csv\"\n",
    "    img_name_dpy23 = \"C1-\" + img_name_mdh1[3:]\n",
    "    s_dataset_dpy23 = folder_path + \"csv-before/\" + img_name_dpy23 + \".csv\"\n",
    "    ps_dataset_dpy23 = folder_path + \"csv-parameters/\" + img_name_dpy23 + \".csv\"\n",
    "    \n",
    "    if(not os.path.exists(s_dataset_mdh1) or not os.path.exists(s_dataset_dpy23)):\n",
    "        # print(\"doesn't exist\")\n",
    "        continue\n",
    "    try:\n",
    "        print(s_dataset_mdh1)\n",
    "        print(s_dataset_dpy23)\n",
    "        \n",
    "        # print(\"Processing:\", dataset[idx]) \n",
    "        z_dpy23, I_dpy23 = load_data(s_dataset_dpy23)\n",
    "        z_mdh1, I_mdh1 = load_data(s_dataset_mdh1)\n",
    "\n",
    "        # load the parameters from file\n",
    "        coeff_dpy23 = load_params(ps_dataset_dpy23)\n",
    "        coeff_mdh1 = load_params(ps_dataset_mdh1)\n",
    "\n",
    "        # print(title, \":\", coeff)  \n",
    "        # print('from {0} to {1}'.format(np.min(z), np.max(z)))\n",
    "\n",
    "        x_dpy23_fit = np.linspace(np.min(z_dpy23), np.max(z_dpy23)) \n",
    "        y_dpy23_fit = g_x(coeff_dpy23[::-1], x_dpy23_fit) \n",
    "        \n",
    "        x_mdh1_fit = np.linspace(np.min(z_mdh1), np.max(z_mdh1))\n",
    "        y_mdh1_fit = g_x(coeff_mdh1[::-1], x_mdh1_fit) \n",
    "\n",
    "        # construct the intron curve\n",
    "        coeff_intron = compute_average_curve(coeff_dpy23, coeff_mdh1)\n",
    "        z_intron_min, z_intron_max = find_min_max(z_dpy23, z_mdh1)\n",
    "        x_intron_fit = np.linspace(z_intron_min, z_intron_max)\n",
    "        y_intron_fit = g_x(coeff_intron[::-1], x_intron_fit) \n",
    "        \n",
    "        # feedback\n",
    "        plt.figure(figsize=(8,5))\n",
    "        title = create_title(s_dataset_dpy23, name_id=5)[3:]\n",
    "        plt.title(title)\n",
    "        \n",
    "        plt.plot(x_dpy23_fit, y_dpy23_fit, linewidth=5, label=labels[0])\n",
    "        plt.plot(x_mdh1_fit, y_mdh1_fit, linewidth=5, label=labels[1])\n",
    "        \n",
    "        plt.plot(x_intron_fit, y_intron_fit, linewidth=5, label=labels[2])\n",
    "        \n",
    "        x_limits = [z_min, z_max]\n",
    "        y_limits = [-0.05, 1.05]\n",
    "        \n",
    "        axes = plt.gca()\n",
    "        axes.set_xlim(x_limits)\n",
    "        axes.set_ylim(y_limits)\n",
    "\n",
    "        plt.xlabel('z-slice')\n",
    "        plt.ylabel('intensity')\n",
    "        \n",
    "        info_text_dpy23 = \"Coeff (dpy23): \" + str(['%.2e' % elem for elem in coeff_dpy23])\n",
    "        info_text_mdh1 = \"Coeff (mdh1): \" + str(['%.2e' % elem for elem in coeff_mdh1])\n",
    "        info_text = info_text_dpy23 + \"\\n\" + info_text_mdh1\n",
    "        plt.text(x_limits[0] + (x_limits[1] - x_limits[0])*0.02, y_limits[0] + (y_limits[1] - y_limits[0])*0.04, info_text, color='black', bbox=dict(facecolor='white', alpha=1))\n",
    "\n",
    "        plt.legend(loc = 'upper right')\n",
    "        full_path_to_use = folder_path + \"img-overlapped/\" \n",
    "        if not os.path.exists(full_path_to_use):\n",
    "            os.makedirs(full_path_to_use)\n",
    "        plt.savefig(full_path_to_use + title + \".pdf\")\n",
    "        \n",
    "        plt.show()\n",
    "    except(RuntimeError, TypeError, ValueError, StopIteration):\n",
    "        print(\"There was an exception but we\\'ll fix it for you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
