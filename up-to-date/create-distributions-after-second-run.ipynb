{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# want to see the images inline\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import gamma\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import special\n",
    "\n",
    "from configparser import ConfigParser\n",
    "\n",
    "import utils as utils\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['config.ini']"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read config file \n",
    "config = ConfigParser()\n",
    "config.read('config.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PARAMS = config.get('main', 'PARAMS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FOLDER = config.get(PARAMS, 'FOLDER')\n",
    "EXPERIMENT = config.get(PARAMS, 'EXPERIMENT')\n",
    "DB_FILENAME = config.get(PARAMS, 'DB_FILENAME')\n",
    "TYPE = config.get(PARAMS, 'TYPE')\n",
    "COLOR = config.get(PARAMS, 'COLOR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bins:  (100,)\n"
     ]
    }
   ],
   "source": [
    "# some const params for all graphs\n",
    "num_bins = 100\n",
    "# graph [xmin, xmax]\n",
    "xmin = -0.2\n",
    "xmax = 3.2\n",
    "binwidth = (xmax - xmin)/(num_bins - 1)\n",
    "\n",
    "bins = np.arange(xmin, xmax + binwidth, binwidth)\n",
    "print ('bins: ', bins.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# important indices\n",
    "type_columns = ['c0_type', 'c1_type', 'c2_type']\n",
    "stain_prefix = np.array([['C0-', 'C1-', 'C2-', 'C3-', 'C4-']])\n",
    "filename_column = 'cropped_image_file'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read the db and parse images that we want to process\n",
    "df_path = os.path.join(FOLDER, 'smFISH-database', DB_FILENAME)\n",
    "df = pd.read_csv(df_path, \n",
    "                 sep=',', \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: maybe it is necessary to fill in other values here, too\n",
    "# fix missing entries in the colmns that we are planning to use \n",
    "df['cropped_image_file'].fillna('', inplace=True)\n",
    "df['c0_type'].fillna('', inplace=True)\n",
    "df['c1_type'].fillna('', inplace=True)\n",
    "df['c2_type'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dff = df[df['cropped_image_file'].apply(lambda x: x.startswith(EXPERIMENT))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# seems to be working\n",
    "row, col = np.where(dff[type_columns].applymap(lambda x: x == TYPE))\n",
    "n_samples = dff.shape[0]\n",
    "new_prefix = np.repeat(stain_prefix, n_samples, axis=0)[row, col]\n",
    "new_filename = dff[filename_column].values[row]\n",
    "full_filenames = [\"{}{}\".format(a_, b_[:-4]) for a_, b_ in zip(new_prefix, new_filename)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4324f0daa740b09aa521f40c209aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "pbar = tqdm(total=len(full_filenames))\n",
    "for ff in full_filenames: \n",
    "    tmp = os.path.join(FOLDER, \"csv-2\", ff + \".csv\")\n",
    "    dataset.append(tmp)\n",
    "    pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# center_path = os.path.join(FOLDER, \"centers\", \"all-centers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 0 files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6811f2c444014655ba637f0734f85627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# have to perform this step multiple times and choose the best one \n",
    "# perform n_fits with different initial parameters\n",
    "# n_fits = 10\n",
    "\n",
    "center_set = {}\n",
    "\n",
    "print(f'Processing: {len(dataset)} files') \n",
    "\n",
    "# actual plotting \n",
    "pbar = tqdm(total=len(dataset))\n",
    "for d in dataset:    \n",
    "    pbar.update(1) \n",
    "    if(not os.path.exists(d)):\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        # create the canvas\n",
    "        fig = plt.figure(figsize=(8,5))\n",
    "        title = utils.create_title(d, name_id=-1)\n",
    "        fig.suptitle(title + \" / \" + TYPE)\n",
    "\n",
    "        # load the data and scale it accordingly\n",
    "        I = utils.load_data(d, skiprows_=0)\n",
    "\n",
    "        # calculate the params for gauss fit\n",
    "        binned_values, real_bins = np.histogram(I, bins)\n",
    "        use_median = np.median(I)\n",
    "        # inititally there was use_median/2 \n",
    "        fit_alpha, fit_loc, fit_beta = gamma.fit(I, \n",
    "                                                 loc=use_median/2, \n",
    "                                                 scale=1/np.max(binned_values),\n",
    "                                                )\n",
    "        # normalization factor\n",
    "        factor = np.sum(binned_values*np.diff(real_bins))\n",
    "        yhat = factor*gamma.pdf(real_bins, \n",
    "                                fit_alpha, \n",
    "                                fit_loc, \n",
    "                                fit_beta,\n",
    "                               )\n",
    "        if (np.any(np.isnan(yhat))):\n",
    "            plt.close()\n",
    "            continue     \n",
    "            \n",
    "        x = np.linspace(xmin, xmax, 1000)\n",
    "        y = factor*gamma.pdf(x, \n",
    "                             fit_alpha, \n",
    "                             fit_loc, \n",
    "                             fit_beta)\n",
    "        plt.hist(I, \n",
    "                 bins=bins, \n",
    "                 color=COLOR, \n",
    "                 label=TYPE, \n",
    "                 density=False,\n",
    "                )\n",
    "        plt.plot(x, \n",
    "                 y, \n",
    "                 linewidth=5, \n",
    "                 color='#66A5AD',\n",
    "                )   \n",
    "        # vertical line for center\n",
    "        plt.axvline(x=real_bins[np.argmax(yhat)], \n",
    "                    linestyle=\"--\", \n",
    "                    linewidth=5, \n",
    "                    color='#66A5AD',\n",
    "                   )\n",
    "\n",
    "        error = utils.fitter_meter(binned_values, yhat[:-1])\n",
    "\n",
    "        # print(\"error: L1, L2\", error)\n",
    "        # print(\"peak center:\", real_bins[np.argmax(yhat)])\n",
    "\n",
    "        # reasonable adjustments to make the data look nicer\n",
    "        plt.xlabel('intensity')\n",
    "        plt.ylabel('# spots')\n",
    "\n",
    "        info_text = \"Total: \" + str(I.shape[0]) + \"\\n\" + \"Peak: \" +  str('%.2f' % real_bins[np.argmax(yhat)]) + \"\\n\" + \"L1: \" + str('%.2f' % error[0]) + \"\\n\" + \"L2: \" +  str('%.2f' % error[1]) \n",
    "\n",
    "        x_limits = [xmin, xmax]\n",
    "        ymax = np.max(np.histogram(I, bins)[0])\n",
    "        y_limits = [0, ymax]\n",
    "\n",
    "        plt.text(x_limits[1] - (x_limits[1] - x_limits[0])*0.15, y_limits[1]*0.8, info_text, color='black', bbox=dict(facecolor='white', alpha=1))\n",
    "        plt.xlim([xmin, xmax])\n",
    "\n",
    "        # save the peak values for further \n",
    "        center_set[title] = real_bins[np.argmax(yhat)]  \n",
    "        folder_path = os.path.join(FOLDER, \"histograms-2\", TYPE)\n",
    "\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "            \n",
    "        plt.savefig(os.path.join(folder_path, title + \".pdf\"))\n",
    "        # plt.show()\n",
    "        # break\n",
    "        plt.close()\n",
    "    except(RuntimeError, TypeError, ValueError):\n",
    "        print(\"There was an exception but we\\'ll fix it for you\")\n",
    "pbar.close()\n",
    "# df_center = pd.DataFrame(list(center_set.items()), columns=['filename', 'center'])\n",
    "# if (os.path.exists(center_path)):\n",
    "#     df_center.to_csv(center_path, index=False, header=False, encoding='utf-8', mode = 'a')\n",
    "# else:\n",
    "#     df_center.to_csv(center_path, index=False, header=True, encoding='utf-8', mode = 'w' )\n",
    "#     print (df_center)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wdr-5.2_ex'"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cb428'"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pretty-graphs)",
   "language": "python",
   "name": "pretty-graphs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
