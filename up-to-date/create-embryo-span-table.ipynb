{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import utils as utils\n",
    "\n",
    "from configparser import ConfigParser, ExtendedInterpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read config file \n",
    "config = ConfigParser(interpolation=ExtendedInterpolation())\n",
    "config.read('config.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = config.get('main', 'ROOTFOLDER')\n",
    "DB_FILENAME = config.get('main', 'DB_FILENAME')\n",
    "TYPES = json.loads(config.get(\"main\",\"TYPES\"))\n",
    "SPAN_FILENAME = config.get(\"main\", \"SPAN_FILENAME\")\n",
    "\n",
    "DB_FILENAME = config.get(\"main\", \"DB_FILENAME\")\n",
    "DB_NEW_FILENAME = config.get(\"main\", \"DB_NEW_FILENAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(FOLDER, \"smFISH-database\", SPAN_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important indices\n",
    "type_columns = ['c0_type', 'c1_type', 'c2_type']\n",
    "stain_prefix = np.array([['C0-', 'C1-', 'C2-', 'C3-', 'C4-']])\n",
    "filename_column = 'cropped_image_file'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read the db and parse images that we want to process\n",
    "df_path = os.path.join(FOLDER, 'smFISH-database', DB_FILENAME)\n",
    "df = pd.read_csv(df_path, \n",
    "                 sep=',', \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: maybe it is necessary to fill in other values here, too\n",
    "# fix missing entries in the colmns that we are planning to use \n",
    "df['cropped_image_file'].fillna('', inplace=True)\n",
    "df['c0_type'].fillna('', inplace=True)\n",
    "df['c1_type'].fillna('', inplace=True)\n",
    "df['c2_type'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dff = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seems to be working\n",
    "row, col = np.where(dff[type_columns].applymap(lambda x: x in TYPES))\n",
    "n_samples = dff.shape[0]\n",
    "new_prefix = np.repeat(stain_prefix, n_samples, axis=0)[row, col]\n",
    "new_filename = dff[filename_column].values[row]\n",
    "full_filenames = [\"{}{}\".format(a_, b_[:-4]) for a_, b_ in zip(new_prefix, new_filename)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = []\n",
    "pbar = tqdm(total=len(full_filenames))\n",
    "for ff in full_filenames: \n",
    "    tmp = os.path.join(FOLDER, \"csv-2\", ff + \".csv\")\n",
    "    dataset.append(tmp)\n",
    "    pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'Processing: {len(dataset)} files') \n",
    "\n",
    "# TODO: consider preallocation\n",
    "df = pd.DataFrame(columns=[\"image\", \"span\"])\n",
    "# actual plotting \n",
    "pbar = tqdm(total=len(dataset))\n",
    "for d in dataset:    \n",
    "    pbar.update(1) \n",
    "    if(not os.path.exists(d)):\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        \n",
    "        # load the data and scale it accordingly\n",
    "        I, z = utils.load_i_z(d, skiprows_=0)\n",
    "\n",
    "        df = df.append(\n",
    "            {\"image\": d.split(\"/\")[-1][:-4], \n",
    "             \"span\": round(max(z) - min(z), 2)\n",
    "            }, \n",
    "            ignore_index=True,\n",
    "        )\n",
    " \n",
    "    except(RuntimeError, TypeError, ValueError):\n",
    "        print(\"There was an exception but we\\'ll fix it for you\")\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"channel\"] = df[\"image\"].apply(lambda x: x[:2].lower() + '_span')\n",
    "df[\"image\"] = df[\"image\"].apply(lambda x: x[3:] + '.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df.pivot_table(\n",
    "    values='span', \n",
    "    index='image', \n",
    "    columns='channel',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.to_csv(os.path.join(FOLDER, \"smFISH-database\", SPAN_FILENAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = os.path.join(FOLDER, \"smFISH-database\", DB_FILENAME)\n",
    "df = pd.read_csv(df_path, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df), len(df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.merge(dff, df_out, how='left',left_on='cropped_image_file', right_on='image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_out.to_csv(os.path.join(FOLDER, \"smFISH-database\", SATURATION_NEW_FILENAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = dff.rename(columns={\"Unnamed: 0\": \"\"})\n",
    "dff.to_csv(os.path.join(FOLDER, \"smFISH-database\", DB_NEW_FILENAME), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "state": {
    "9241e0b020c2460daa688eff85232332": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "981b0f2f137246d0a1c687d330727dba": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
