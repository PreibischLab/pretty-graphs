{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a script for making pretty plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv as csv\n",
    "\n",
    "# general \n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from functools import reduce\n",
    "import re\n",
    "\n",
    "from sklearn import linear_model, datasets\n",
    "\n",
    "from numpy import polyval\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for loading one data-set\n",
    "def load_data(file_path, skiprows_=1):\n",
    "    data = np.loadtxt(file_path, delimiter = '\\t', skiprows=skiprows_)\n",
    "    # print(data.shape) \n",
    "    # handles some weird cases, e.g. when there is no data in the file\n",
    "    if (len(data.shape) < 2):\n",
    "        data = data[None, :]\n",
    "    if (data.shape[1] == 0):\n",
    "        I = np.array([0])\n",
    "        z = np.array([0])\n",
    "    else:\n",
    "        I = data[:, -1]\n",
    "        z = data[:, -2]\n",
    "    return (z, I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the y coordinate for the given line\n",
    "# y = kx + b; also works with vectors\n",
    "def f_x(x_, k_, b_):\n",
    "    return k_*x_ + b_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_x(a, x):\n",
    "    return polyval(a, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general setup for pretty images \n",
    "num_files = 16\n",
    "lines_params = np.zeros([num_files, 2])\n",
    "channel_id = 1 # 1,2,3\n",
    "# folder_path = '/Users/kkolyva/Desktop/2018-04-18-08-29-25-test/test/2018-04-24-15-33-21-median-median-first-test/csv/' \n",
    "image = 'N2_dpy-23_ex_int_ama-1_016'\n",
    "Ia_min, Ia_max = 0, 40000\n",
    "za_min, za_max = 0, 55\n",
    "\n",
    "# folder_path = '/Volumes/1TB/2018-05-15-12-30-27-SEA12-full-stack/'\n",
    "folder_path = '/Volumes/MILKYKLIM⁩/⁨2019-07-08-exp⁩/N2⁩'\n",
    "# folder_path = '/Volumes/1TB/2018-06-14-12-36-00-N2-full-stack/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible labels \n",
    "stain = ['DPY-23_EX', 'WDR-5.2', 'MDH-1']\n",
    "stage = 'E' # only embryos\n",
    "comment = '' # only empty ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important indices\n",
    "stain_columns = ['C0_stain', 'C1_stain', 'C2_stain', 'C3_stain', 'C4_stain']\n",
    "type_columns = ['C0_type', 'C1_type', 'C2_type', 'C3_type', 'C4_type']\n",
    "stain_prefix = np.array([['C1-', 'C2-', 'C3-', 'C4-', 'C5-']])\n",
    "ext = '.csv'\n",
    "filename_column = 'new filename'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'/Volumes/MILKYKLIM\\xe2\\x81\\xa9/\\xe2\\x81\\xa82019-07-08-exp\\xe2\\x81\\xa9/N2\\xe2\\x81\\xa9smFISH-database/N2-Table 1.csv' does not exist: b'/Volumes/MILKYKLIM\\xe2\\x81\\xa9/\\xe2\\x81\\xa82019-07-08-exp\\xe2\\x81\\xa9/N2\\xe2\\x81\\xa9smFISH-database/N2-Table 1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ff79ba9cad4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# read the db and parse images that we want to process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"smFISH-database/N2-Table 1.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pretty-graphs/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pretty-graphs/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pretty-graphs/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pretty-graphs/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pretty-graphs/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/Volumes/MILKYKLIM\\xe2\\x81\\xa9/\\xe2\\x81\\xa82019-07-08-exp\\xe2\\x81\\xa9/N2\\xe2\\x81\\xa9smFISH-database/N2-Table 1.csv' does not exist: b'/Volumes/MILKYKLIM\\xe2\\x81\\xa9/\\xe2\\x81\\xa82019-07-08-exp\\xe2\\x81\\xa9/N2\\xe2\\x81\\xa9smFISH-database/N2-Table 1.csv'"
     ]
    }
   ],
   "source": [
    "# read the db and parse images that we want to process\n",
    "df = pd.read_csv(folder_path + \"smFISH-database/N2-Table 1.csv\", sep=',', na_values=['']);\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is general\n",
    "# filter to have only *good* and *embryo* files\n",
    "good_indices = np.logical_and((df['stage'] == stage).tolist() , (df['comment'].isnull()).tolist())\n",
    "good_indices.shape[0]\n",
    "print(np.sum(good_indices == True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose necessary stains\n",
    "dataset1 = []\n",
    "df_good = (df[type_columns].astype(np.object) == stain[0]).loc[good_indices, :]\n",
    "row, col = np.where(df_good)\n",
    "n_samples = df.shape[0]\n",
    "new_prefix = np.repeat(stain_prefix, n_samples, axis=0)[row, col]\n",
    "new_filename = df[filename_column].loc[good_indices].as_matrix()[row]\n",
    "dataset1 = [\"{}{}\".format(a_, b_) for a_, b_ in zip(new_prefix, new_filename)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose necessary stains\n",
    "dataset2 = []\n",
    "df_good = (df[type_columns].astype(np.object) == stain[1]).loc[good_indices, :]\n",
    "row, col = np.where(df_good)\n",
    "n_samples = df.shape[0]\n",
    "new_prefix = np.repeat(stain_prefix, n_samples, axis=0)[row, col]\n",
    "new_filename = df[filename_column].loc[good_indices].as_matrix()[row]\n",
    "dataset2 = [\"{}{}\".format(a_, b_) for a_, b_ in zip(new_prefix, new_filename)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose necessary stains\n",
    "dataset3 = []\n",
    "df_good = (df[type_columns].astype(np.object) == stain[2]).loc[good_indices, :]\n",
    "row, col = np.where(df_good)\n",
    "n_samples = df.shape[0]\n",
    "new_prefix = np.repeat(stain_prefix, n_samples, axis=0)[row, col]\n",
    "new_filename = df[filename_column].loc[good_indices].as_matrix()[row]\n",
    "dataset3 = [\"{}{}\".format(a_, b_) for a_, b_ in zip(new_prefix, new_filename)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_title(path, name_id=8):\n",
    "    # get the name of the initial image\n",
    "    image_name = path.split(\"/\")[name_id] # was 8\n",
    "    # print(path.split(\"/\"))\n",
    "    # create the full title \n",
    "    title = image_name[:-4]\n",
    "    return title\n",
    "# create_title(\"/Users/kkolyva/Desktop/n2/N2-results/all/C1-N2_9.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = ['DPY-23_EX'] # ['DPY-23_EX', 'WDR-5.2', 'MDH-1']\n",
    "color = '#BA5536'\n",
    "if labels[0] == 'MDH-1':\n",
    "    color = \"#693D3D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# actual plotting \n",
    "img_before = \"\"\n",
    "if (False):\n",
    "    img_before = \"-before\" \n",
    "\n",
    "dataset_to_use = dataset1\n",
    "if labels[0] == 'MDH-1':\n",
    "    dataset_to_use = dataset3\n",
    "    \n",
    "dataset = []\n",
    "p_dataset = []\n",
    "for j in range(0, len(dataset_to_use)):\n",
    "    tmp = folder_path + \"csv\" + img_before + \"/\" + dataset_to_use[j] + \".csv\"\n",
    "    dataset.append(tmp)\n",
    "    print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the parameters from file for the fitter\n",
    "def load_params(file_path):\n",
    "    data = np.loadtxt(file_path, delimiter = '\\t', skiprows=0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# actual plotting \n",
    "for idx in range(0, len(dataset)):\n",
    "    # feedback\n",
    "    \n",
    "    if(not os.path.exists(dataset[idx])):\n",
    "        # print(\"doesn't exist\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # print(\"Processing:\", dataset[idx]) \n",
    "        z,I = load_data(dataset[idx], skiprows_=0)\n",
    "\n",
    "        plt.figure(figsize=(8,5))\n",
    "\n",
    "        title = create_title(dataset[idx], name_id=5)\n",
    "        plt.title(title + \" / \" + labels[0])\n",
    "\n",
    "        plt.plot(z, I, 'o', color=color)\n",
    "\n",
    "        x_limits = [0, 120]\n",
    "        y_limits = [-0.2, 1.0]\n",
    "\n",
    "        axes = plt.gca()\n",
    "        axes.set_xlim(x_limits)\n",
    "        axes.set_ylim(y_limits)\n",
    "\n",
    "        plt.xlabel('z-slice')\n",
    "        plt.ylabel('intensity')\n",
    "\n",
    "        info_text = \"Total: \" + str(I.shape[0])\n",
    "        plt.text(x_limits[0] + (x_limits[1] - x_limits[0])*0.02, y_limits[0] + (y_limits[1] - y_limits[0])*0.04, info_text, color='black', bbox=dict(facecolor='white', alpha=1))\n",
    "\n",
    "        # plt.legend(loc = 'upper right')      \n",
    "        full_path_to_use = folder_path + \"img\"  + img_before + \"/\"+ labels[0] + \"/\" \n",
    "        if not os.path.exists(full_path_to_use):\n",
    "            os.makedirs(full_path_to_use)\n",
    "        plt.savefig(full_path_to_use + title + \".pdf\")\n",
    "        \n",
    "        plt.show()\n",
    "    except(RuntimeError, TypeError, ValueError):\n",
    "        print(\"There was an exception but we\\'ll fix it for you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
