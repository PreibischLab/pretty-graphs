{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# what are the steps taht we perform here\n",
    "\n",
    "# [x] grab the data \n",
    "# [] run multiple gauss fits over the date with multiple initialization points \n",
    "# [] check what is the result for each run and which one gives the least error\n",
    "# [] take only 70% of the points \n",
    "# [] write the result to the csv\n",
    "\n",
    "# [] final consolidated table -> made per channel per type of gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# want to see the images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# imports\n",
    "# general \n",
    "import os\n",
    "import glob\n",
    "from functools import reduce\n",
    "import re\n",
    "import csv as csv\n",
    "# scientific \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import linear_model, datasets\n",
    "from scipy.stats import norm, gamma\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import special\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# simple gamma function\n",
    "def g_x(x, a, c):\n",
    "    return x**(a - 1)*np.exp(-x)/special.gamma(a) + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for loading one data-set\n",
    "def load_data(file_path, skiprows_=1):\n",
    "    data = np.loadtxt(file_path, delimiter = '\\t', skiprows=skiprows_)\n",
    "    # print(data.shape) \n",
    "    # handles some weird cases, e.g. when there is no data in the file\n",
    "    if (len(data.shape) < 2):\n",
    "        data = data[None, :]\n",
    "    if (data.shape[1] == 0):\n",
    "        I = np.array([0])\n",
    "    else:\n",
    "        I = data[:, -1]\n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some folder magic \n",
    "# folder = '/Volumes/1TB/2018-05-15-12-30-27-SEA12-full-stack/' # folder contains z-corrected spots \n",
    "folder = '/Volumes/1TB/2018-06-14-12-36-00-N2-full-stack/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some const params for all graphs\n",
    "num_bins = 100; \n",
    "# graph [xmin, xmax]\n",
    "xmin = 0\n",
    "xmax = 3\n",
    "\n",
    "binwidth = (xmax - xmin)/(num_bins - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins = np.arange(xmin, xmax + binwidth, binwidth)\n",
    "print ('bins: ', bins.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for testing \n",
    "filename = 'C1-N2_311'\n",
    "filepath =  folder + \"csv-2/\" + filename + '.csv'\n",
    "I = load_data(filepath)\n",
    "\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "title = 'C1-N2_311'\n",
    "plt.title(title)\n",
    "    \n",
    "plt.xlabel('intensity')\n",
    "plt.ylabel('# spots')\n",
    "\n",
    "print(\"I_min:\", min(I), \"I_max:\", max(I))\n",
    "\n",
    "I_res = I\n",
    "fit_alpha, fit_loc, fit_beta = gamma.fit(I_res)\n",
    "print(fit_alpha, fit_loc, fit_beta)\n",
    "\n",
    "plt.hist(I, bins=bins, color='pink', normed=True); # \n",
    "# plt.text(0.9*xmax, 0.1, \"Total: \" + str(I.shape[0]), color='black', bbox=dict(facecolor='white', alpha=1))\n",
    "\n",
    "info_text = \"Total: \" + str(I.shape[0])\n",
    "\n",
    "x_limits = [xmin, xmax]\n",
    "ymax = np.max(np.histogram(I, bins)[0])\n",
    "y_limits = [0, ymax]\n",
    "\n",
    "plt.text(x_limits[1] - (x_limits[1] - x_limits[0])*0.1, y_limits[0] + (y_limits[1] - y_limits[0])*0.04, info_text, color='black', bbox=dict(facecolor='white', alpha=1))\n",
    "   \n",
    "\n",
    "x = np.linspace(xmin, xmax, 1000)\n",
    "y = gamma.pdf(x, fit_alpha, fit_loc, fit_beta)\n",
    "plt.plot(x,y)\n",
    "\n",
    "print(\"peak center:\", x[np.argmax(y)])\n",
    "\n",
    "plt.xlim([xmin, xmax])\n",
    "\n",
    "# plt.legend(loc = 'upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# possible labels \n",
    "stain = ['DPY-23_EX', 'WDR-5.2', 'MDH-1']\n",
    "stage = 'E' # only embryos\n",
    "comment = '' # only empty ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# important indices\n",
    "stain_columns = ['C0_stain', 'C1_stain', 'C2_stain', 'C3_stain', 'C4_stain']\n",
    "type_columns = ['C0_type', 'C1_type', 'C2_type', 'C3_type', 'C4_type']\n",
    "stain_prefix = np.array([['C1-', 'C2-', 'C3-', 'C4-', 'C5-']])\n",
    "ext = '.csv'\n",
    "filename_column = 'new filename'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read the db and parse images that we want to process\n",
    "df = pd.read_csv(folder + \"smFISH-database/N2-Table 1.csv\", sep=',', na_values=['']);\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# this is general\n",
    "# filter to have only *good* and *embryo* files\n",
    "good_indices = np.logical_and((df['stage'] == stage).tolist() , (df['comment'].isnull()).tolist())\n",
    "good_indices.shape[0]\n",
    "\n",
    "\n",
    "print(np.sum(good_indices == True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# choose necessary stains\n",
    "dataset1 = []\n",
    "df_good = (df[type_columns].astype(np.object) == stain[0]).loc[good_indices, :]\n",
    "row, col = np.where(df_good)\n",
    "n_samples = df.shape[0]\n",
    "new_prefix = np.repeat(stain_prefix, n_samples, axis=0)[row, col]\n",
    "new_filename = df[filename_column].loc[good_indices].as_matrix()[row]\n",
    "dataset1 = [\"{}{}\".format(a_, b_) for a_, b_ in zip(new_prefix, new_filename)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# choose necessary stains\n",
    "dataset2 = []\n",
    "df_good = (df[type_columns].astype(np.object) == stain[1]).loc[good_indices, :]\n",
    "row, col = np.where(df_good)\n",
    "n_samples = df.shape[0]\n",
    "new_prefix = np.repeat(stain_prefix, n_samples, axis=0)[row, col]\n",
    "new_filename = df[filename_column].loc[good_indices].as_matrix()[row]\n",
    "dataset2 = [\"{}{}\".format(a_, b_) for a_, b_ in zip(new_prefix, new_filename)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# choose necessary stains\n",
    "dataset3 = []\n",
    "df_good = (df[type_columns].astype(np.object) == stain[2]).loc[good_indices, :]\n",
    "row, col = np.where(df_good)\n",
    "n_samples = df.shape[0]\n",
    "new_prefix = np.repeat(stain_prefix, n_samples, axis=0)[row, col]\n",
    "new_filename = df[filename_column].loc[good_indices].as_matrix()[row]\n",
    "dataset3 = [\"{}{}\".format(a_, b_) for a_, b_ in zip(new_prefix, new_filename)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(dataset1) + len(dataset2) + len(dataset3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_title(path, name_id=8):\n",
    "    # get the name of the initial image\n",
    "    image_name = path.split(\"/\")[name_id] # was 8\n",
    "    # print(path.split(\"/\"))\n",
    "    # create the full title \n",
    "    title = image_name[:-4]\n",
    "    return title\n",
    "# create_title(\"/Users/kkolyva/Desktop/n2/N2-results/all/C1-N2_9.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = ['DPY-23_EX'] # ['DPY-23_EX', 'WDR-5.2', 'MDH-1']\n",
    "color = '#BA5536'\n",
    "if labels[0] == 'MDH-1':\n",
    "    color = \"#693D3D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# actual plotting \n",
    "\n",
    "dataset_to_use = dataset1\n",
    "if labels[0] == 'MDH-1':\n",
    "    dataset_to_use = dataset3\n",
    "    \n",
    "dataset = []\n",
    "p_dataset = []\n",
    "for j in range(0, len(dataset_to_use)):\n",
    "    tmp = folder + \"csv-2/\" + dataset_to_use[j] + \".csv\"\n",
    "    dataset.append(tmp)\n",
    "    print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# how good is fitter-meter?\n",
    "def fitter_meter(y, y_hat):\n",
    "    return [mean_absolute_error(y,y_hat), np.sqrt(mean_squared_error(y,y_hat))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# have to perform this step multiple times and choose the best one \n",
    "# perform n_fits with different initial parameters\n",
    "# n_fits = 10\n",
    "\n",
    "folder_path = folder + \"histograms-2/\" + labels[0] + \"/\"\n",
    "\n",
    "# actual plotting \n",
    "for idx in range(0, len(dataset)):    \n",
    "    if(not os.path.exists(dataset[idx])):\n",
    "        # print(\"doesn't exist\")\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        # create the canvas\n",
    "        fig = plt.figure(figsize=(8,5))\n",
    "        title = create_title(dataset[idx], name_id=5)\n",
    "        fig.suptitle(title + \" / \" + labels[0])\n",
    "\n",
    "        # load the data and scale it accordingly\n",
    "        I = load_data(dataset[idx], skiprows_=0)\n",
    "\n",
    "        # some const params for all graphs\n",
    "        # num_bins = 100; \n",
    "        # graph [xmin, xmax]\n",
    "        # xmin = np.min(I)\n",
    "        # xmax = np.max(I)\n",
    "        # binwidth = (xmax - xmin)/(num_bins - 1)\n",
    "        # bins = np.arange(xmin, xmax + binwidth, binwidth)\n",
    "\n",
    "        I_res = I\n",
    "        # calculate the params for gauss fit\n",
    "        binned_values, real_bins = np.histogram(I, bins)\n",
    "        use_median = np.median(I_res)\n",
    "        # inititally there was use_median/2 \n",
    "        fit_alpha, fit_loc, fit_beta = gamma.fit(I_res, loc=use_median/2, scale=1/np.max(binned_values))\n",
    "        # normalization factor\n",
    "        factor = np.sum(binned_values*np.diff(real_bins))\n",
    "\n",
    "        plt.hist(I, bins=bins, color=color, label=labels, normed=False)\n",
    "\n",
    "        x = np.linspace(xmin, xmax, 1000)\n",
    "        y = gamma.pdf(x, fit_alpha, fit_loc, fit_beta)*factor\n",
    "        plt.plot(x,y, linewidth=5, color='#66A5AD')\n",
    "        yhat = gamma.pdf(real_bins, fit_alpha, fit_loc, fit_beta)*factor\n",
    "\n",
    "        # vertical line for center\n",
    "        plt.axvline(x=real_bins[np.argmax(yhat)], linestyle=\"--\", linewidth=5, color='#66A5AD')\n",
    "\n",
    "        if (np.any(np.isnan(yhat))):\n",
    "            continue\n",
    "\n",
    "        error = fitter_meter(binned_values, yhat[:-1])\n",
    "\n",
    "        print(\"error: L1, L2\", error)\n",
    "        print(\"peak center:\", real_bins[np.argmax(yhat)])\n",
    "\n",
    "        # reasonable adjustments to make the data look nicer\n",
    "        plt.xlabel('intensity')\n",
    "        plt.ylabel('# spots')\n",
    "\n",
    "        info_text = \"Total: \" + str(I.shape[0]) + \"\\n\" + \"Peak: \" +  str('%.2f' % real_bins[np.argmax(yhat)]) + \"\\n\" + \"L1: \" + str('%.2f' % error[0]) + \"\\n\" + \"L2: \" +  str('%.2f' % error[1]) \n",
    "\n",
    "        x_limits = [xmin, xmax]\n",
    "        ymax = np.max(np.histogram(I, bins)[0])\n",
    "        y_limits = [0, ymax]\n",
    "\n",
    "        plt.text(x_limits[1] - (x_limits[1] - x_limits[0])*0.15, y_limits[1]*0.8, info_text, color='black', bbox=dict(facecolor='white', alpha=1))\n",
    "        plt.xlim(x_limits)\n",
    "\n",
    "        # save the peak values for further \n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "        plt.savefig(folder_path + title + \".pdf\") \n",
    "        plt.show()\n",
    "    except(RuntimeError, TypeError, ValueError):\n",
    "        print(\"There was an exception but we\\'ll fix it for you\")\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ?plt.hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# make the plot with the total number of the detections\n",
    "folder_path = folder + \"total-2/\" + labels[0] + \"/\"\n",
    "print(folder_path)\n",
    "\n",
    "result_set = {}\n",
    "\n",
    "# actual plotting \n",
    "for idx in range(0, len(dataset)):    \n",
    "    if(not os.path.exists(dataset[idx])):\n",
    "        # print(\"doesn't exist\")\n",
    "        continue\n",
    "   \n",
    "    try:\n",
    "        print(dataset[idx])\n",
    "\n",
    "        # load the data and scale it accordingly\n",
    "        I = load_data(dataset[idx])\n",
    "        I_res = I\n",
    "\n",
    "        # some const params for all graphs\n",
    "        num_bins = 100; \n",
    "        # graph [xmin, xmax]\n",
    "        xmin = 0\n",
    "        xmax = 3\n",
    "        binwidth = (xmax - xmin)/(num_bins - 1)\n",
    "        bins = np.arange(xmin, xmax + binwidth, binwidth)\n",
    "\n",
    "        binned_values, real_bins = np.histogram(I_res, bins)\n",
    "        use_median = np.median(I_res)\n",
    "        # inititally there was use_median/2 \n",
    "        fit_alpha, fit_loc, fit_beta = gamma.fit(I_res, loc=use_median/2, scale=1/np.max(binned_values))\n",
    "        # normalization factor\n",
    "        factor = np.sum(binned_values*np.diff(real_bins))\n",
    "        x = np.linspace(xmin, xmax, 1000)\n",
    "        y = gamma.pdf(x, fit_alpha, fit_loc, fit_beta)*factor\n",
    "        yhat = gamma.pdf(real_bins, fit_alpha, fit_loc, fit_beta)*factor\n",
    "\n",
    "        if (np.any(np.isnan(yhat))):\n",
    "            continue\n",
    "\n",
    "        # should be close to 1\n",
    "        x_center = real_bins[np.argmax(yhat)]\n",
    "\n",
    "        # error less than 15%\n",
    "        print (\"error:\", np.abs(x_center - 1), \"; center:\", x_center)\n",
    "        if (np.abs(x_center - 1) < 0.15):    \n",
    "            title = create_title(dataset[idx], name_id=5)\n",
    "            result_set[title] = len(I)   \n",
    "    except(RuntimeError, TypeError, ValueError, StopIteration):\n",
    "        print(\"There was an exception but we\\'ll fix it for you\")\n",
    "            \n",
    "print(list(result_set.values()))        \n",
    "        \n",
    "# these are subject to change\n",
    "xmin = 0\n",
    "xmax = 4000\n",
    "binwidth = 100\n",
    "num_bins = (xmax - xmin) / binwidth + 1;\n",
    "bins = np.arange(xmin, xmax + binwidth, binwidth)\n",
    "xlimits = [xmin, xmax]\n",
    "\n",
    "spots_total = list(result_set.values())\n",
    "\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "fig.suptitle(labels[0] + \": Total\")\n",
    "plt.hist(spots_total, bins=bins, color=color, label=labels, normed=False)\n",
    "\n",
    "plt.xlabel(\"# spots\")\n",
    "plt.ylabel(\"# embryos\")\n",
    "\n",
    "df_center = pd.DataFrame(list(result_set.items()), columns=['filename', 'total'])\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path )\n",
    "df_center.to_csv(folder_path + labels[0] +\"-total.csv\", index=False, header=True, encoding='utf-8', mode = 'w' )\n",
    "plt.savefig(folder_path + labels[0] + \"-total.pdf\") \n",
    "plt.show()\n",
    "        \n",
    "print (\"DOGE!\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
